# Architecture & Technical Details

This document contains detailed technical documentation for the Stellaris Stats project architecture.

## GraphQL Caching System

The project implements a three-tier caching strategy using Redis to optimize GraphQL query performance for immutable game state data.

### Caching Architecture

#### Tier 1: Response-Level Caching

- **Implementation**: Custom Apollo Server plugin (`src/graphql/responseCache.ts`)
- **Class**: `RedisCache` implementing Apollo's `KeyValueCache` interface
- **Key Prefix**: `graphql:` for all cache entries
- **Key Format**: `graphql:{query-hash}:{variables-hash}` (auto-generated by Apollo)
- **Null Prevention**: Responses containing null values are NOT cached to prevent caching errors

#### Tier 2: Field-Level Caching

- **Implementation**: Manual caching in resolvers (`src/graphql/generated/Gamestate.ts`)
- **Cached Fields**:
  - `Gamestate.budget` - Key: `budget:gamestateId:{id}`
  - `Gamestate.planets` - Key: `planets:gamestateId:{id}`
- **Strategy**: Check cache first, on miss load via DataLoader and cache result
- **TTL**: No expiration (immutable data)

#### Tier 3: DataLoader Batching with Request-Scoped Cache

- **Location**: `src/graphql/dataloaders/`
- **DataLoaders**:
  - `budgetLoader`: Batches budget queries by gamestateId
  - `planetsLoader`: Batches planet queries by gamestateId
  - `gamestatesLoader`: Batches gamestate queries by saveId
- **Purpose**: Prevent N+1 query problems and provide request-level deduplication
- **Lifecycle**: Created per GraphQL request (request-scoped)
- **Database Functions**: Calls batch query functions like `getBudgetBatch()`, `getPlanetsBatch()`

### Redis Configuration

- **Client**: `ioredis` library configured in `src/redis.ts`
- **Environment Variables**:
  - `STELLARIS_STATS_REDIS_HOST` (default: 'redis')
  - `STELLARIS_STATS_REDIS_PORT` (default: 6379)
  - `STELLARIS_STATS_REDIS_DB` (default: 0)
- **Retry Strategy**: Exponential backoff (50ms × attempts, max 2000ms, 3 max retries)
- **Deployment**: Redis 7.4-alpine container with persistent volume storage, internal network only (no exposed ports)

### Cache Control Directives

- **GraphQL Schema**: Uses `@cacheControl` directive in `graphql/schema.graphql`
- **Cached Types**: `Budget` and `Gamestate` types marked with `@cacheControl` (no maxAge specified)
- **Default Behavior**: No caching unless explicit `@cacheControl` directive present
- **TTL Strategy**: No expiration for immutable types (game state data never changes once stored)

### Cache Invalidation

- **Current Implementation**: None
- **Rationale**: Game state data is immutable - once parsed and stored, it never changes
- **Considerations**: Redis memory may grow over time; consider implementing eviction policy (e.g., `allkeys-lru`) if needed

### Query Flow

```
GraphQL Query
  → Apollo Response Cache (check)
    → Resolver Field-Level Cache (check)
      → DataLoader Request Cache (check)
        → Batch Database Query
          → Store in all cache layers
            → Return result
```

## Testing Framework

The project uses end-to-end integration testing with complete database isolation, allowing tests to run in parallel without interference.

### Testing Architecture

#### Test Runner

- **Framework**: Bun (built-in test runner)
- **Test Files**: `tests/**/*.test.ts`
- **Command**: `npm run test:typescript` (uses `dotenvx` to load test environment)
- **Execution**: Parallel by default, each test fully isolated

#### Database Isolation Strategy

- **Pattern**: Database-per-test
- **Implementation**: Each test creates a unique PostgreSQL database using `crypto.randomUUID()`
- **Database Naming**: `stellaris_test_{uuid}` with hyphens replaced by underscores
- **Lifecycle**: Created in `beforeEach`, destroyed in `afterEach`
- **Migrations**: Automatically run on each test database using `node-pg-migrate`
- **Database Services**: Separate PostgreSQL containers in docker-compose: `db-tests` for TypeScript tests, `db-evals` for Python evals

#### Test Infrastructure Components

##### 1. Test Database Manager (`tests/utils/testDatabase.ts`)

Creates and destroys isolated test databases:

```typescript
const testDb = await createTestDatabase()
// Returns: { pool: Pool, dbName: string, dbConfig: PoolConfig }

await destroyTestDatabase(testDb)
```

**Features:**

- Creates unique database with UUID-based name
- Runs all migrations automatically
- Provides dedicated connection pool
- Cleanup ensures no test database leaks

##### 2. Test Server Factory (`tests/utils/testServer.ts`)

Creates Apollo Server configured for testing:

```typescript
const testServer = createTestServer(testDb)
// Returns: { server, pool, cache, mockRedis, cleanup }
```

**Configuration:**

- Uses test database pool
- Mock Redis implementation (in-memory)
- All production plugins (response cache, cache control)
- Client release plugin (auto-releases connections)
- No HTTP layer (uses `executeOperation` directly)

##### 3. GraphQL Client Wrapper (`tests/utils/graphqlClient.ts`)

Type-safe GraphQL query execution:

```typescript
const result = await executeQuery<{
  saves: { filename: string }[]
}>(testServer, query, variables)
// Returns: { data?: T, errors?: GraphQLFormattedError[] }
```

**Features:**

- Creates proper GraphQL context per request
- Includes DataLoaders and cache
- Type-safe response with generics
- Automatic client release via server plugin

##### 4. Fixture Loader (`tests/utils/fixtures.ts`)

Loads SQL fixtures into test database:

```typescript
await loadFixture(testDb.pool, 'saves/basic-save.sql')
await loadFixtures(testDb.pool, ['saves/save1.sql', 'saves/save2.sql'])
```

**Fixture Pattern:**

- Located in `tests/fixtures/`
- Use subqueries for foreign key references
- Sequential execution to maintain FK dependencies
- Example: `(SELECT save_id FROM save WHERE filename = 'test.sav')`

##### 5. Mock Redis (`tests/utils/mockRedis.ts`)

In-memory Redis implementation:

- Implements same interface as `ioredis`
- Compatible with `RedisCache` wrapper
- No external dependencies
- Automatically cleared on cleanup

### Test Configuration

**Environment Files**: Separate env files for tests and evals

| File | Purpose | Database Service |
|------|---------|------------------|
| `.env.stellaris-stats.tests` | TypeScript tests | `db-tests` |
| `.env.stellaris-stats.evals` | Python evals | `db-evals` |

**TypeScript Tests** (`.env.stellaris-stats.tests`):
```bash
STELLARIS_STATS_DB_HOST=db-tests
STELLARIS_STATS_DB_PORT=5432
STELLARIS_STATS_DB_NAME=stellaris_tests
STELLARIS_STATS_DB_USER=stellaris_tests
STELLARIS_STATS_DB_PASSWORD=stellaris_tests_password
```

**Python Evals** (`.env.stellaris-stats.evals`):
```bash
STELLARIS_STATS_DB_HOST=db-evals
STELLARIS_STATS_DB_PORT=5432
STELLARIS_STATS_DB_NAME=stellaris_evals
STELLARIS_STATS_DB_USER=stellaris_evals
STELLARIS_STATS_DB_PASSWORD=stellaris_evals_password
```

**Docker Compose**: Separate database services with inline credentials (no persistent volumes - test databases are ephemeral)

```yaml
db-tests:
  image: postgres:18
  container_name: stellaris-stats_db-tests
  environment:
    POSTGRES_DB: stellaris_tests
    POSTGRES_USER: stellaris_tests
    POSTGRES_PASSWORD: stellaris_tests_password
  networks:
    - stellaris-stats-db-tests-network

db-evals:
  image: postgres:18
  container_name: stellaris-stats_db-evals
  environment:
    POSTGRES_DB: stellaris_evals
    POSTGRES_USER: stellaris_evals
    POSTGRES_PASSWORD: stellaris_evals_password
  networks:
    - stellaris-stats-db-evals-network
```

### Key Implementation Details

**Context Creation Pattern:**

```typescript
const client = await pool.connect()
const contextValue: GraphQLServerContext = {
  client,
  loaders: createDataLoaders(client),
  cache,
}
```

**Client Lifecycle:**

- Client acquired from pool per GraphQL request
- Released automatically by server's `willSendResponse` plugin
- No manual `client.release()` needed in tests
- Tests must `await executeQuery` to ensure cleanup

**Server vs Production:**

- Test server has same plugins as production
- Uses `executeOperation()` instead of HTTP
- No `startStandaloneServer()` call
- Context created per operation, not pre-configured

**Database Naming Constraints:**

- PostgreSQL identifiers use underscores not hyphens
- UUID hyphens replaced: `randomUUID().replace(/-/g, '_')`
- Format: `stellaris_test_550e8400_e29b_41d4_a716_446655440000`

## Parser System

The parser is a background service that periodically reads Stellaris save files, extracts game state data, and stores it in PostgreSQL for analysis via the GraphQL API.

### Parser Architecture

#### Execution Model

- **Interval-Based**: Runs on a configurable interval defined by `STELLARIS_STATS_PARSER_INTERVAL` environment variable
- **Watch Mode**: Uses `tsx watch` for automatic restart on code changes during development
- **Command**: `npm run parser:run -- -g <gamestateId>` or `npm run parser:run -- -l` to list available saves

#### Key Components

**Configuration (`src/parser/parserConfig.ts`)**
- Defines parser-specific configuration schema
- Validates `STELLARIS_STATS_PARSER_INTERVAL` using Zod

**Main Parser (`src/parser/parserMain.ts`)**
- Orchestrates the parsing workflow
- Runs database migrations on startup
- Executes parsing loop at configured intervals
- Handles graceful shutdown (SIGTERM, SIGINT)

**Gamestate Reader (`src/parser/gamestateReader.ts`)**
- Extracts `gamestate` file from ZIP-compressed save files using yauzl-promise
- Returns gamestate data as `Uint8Array` for parsing

**Parser Options (`src/parser/parserOptions.ts`)**
- Parses command-line arguments using Commander
- Supports `-g <gamestateId>` to specify which save to parse
- Supports `-l` to list available gamestate IDs from `/stellaris-data` directory

#### Parsing Workflow

1. **Read Save File**: Extract gamestate from ZIP file at `/stellaris-data/<gamestateId>/ironman.sav`
2. **Parse with Jomini**: Convert Paradox Clausewitz format to JavaScript object
3. **Extract Metadata**: Parse `name` (empire name) and `date` (in-game date) from gamestate
4. **Begin Transaction**: Use `withTx()` helper to wrap all database operations in a transaction
5. **Upsert Save**: Create or update save row with filename (without .sav extension) and name
6. **Check Existence**: Query database for existing gamestate in the same month using `startOfMonth()` comparison
7. **Insert Gamestate**: If no gamestate exists for that month, insert new row with full parsed JSON as JSONB
8. **Populate Budget Tables**: Extract budget data from parsed object and insert into `budget_entry` and `budget_category` tables
9. **Commit Transaction**: Transaction automatically commits on success, rolls back on error

#### Budget Table Population

**Budget Data Extraction:**
- Player country ID: `parsed.player[0].country`
- Budget data path: `parsed.country[playerCountryId].budget.current_month`
- Structure: Three-level nested object with category types (`income`, `expenses`, `balance`), each containing category names (e.g., `country_base`, `armies`, `ships`), which contain resource fields (20 total: `energy`, `minerals`, `alloys`, etc.)

**Database Functions:**
- `populateBudgetTables(client, gamestateId, parsed, logger)` - Main orchestration function in `src/db/budget.ts`
- `insertBudgetEntry(client, entryData)` - Inserts budget_entry row with 20 resource columns, returns budget_entry_id
- `insertBudgetCategory(client, gamestateId, categoryType, categoryName, budgetEntryId)` - Links budget entry to gamestate

**Transaction Atomicity:**
- All parser operations (save upsert, gamestate insert, budget population) wrapped in single transaction using `withTx()` helper
- Ensures budget data is never orphaned from its gamestate
- If budget population fails unexpectedly, entire operation rolls back

**Graceful Error Handling:**
- Missing player country ID: Log warning, skip budget population
- Missing budget data: Log info, skip budget population (normal for some saves)
- Validation errors: Log error with context, skip budget population
- Unexpected errors: Transaction rolls back, error bubbles up
- Budget population is non-critical and won't fail parser iteration for missing/invalid data

#### Database Operations

**Save Management**
- Function: `upsertSave(client, filename, name)` in `src/db/save.ts`
- Uses `ON CONFLICT (filename) DO UPDATE` to handle duplicates
- Updates save name if it changes between parses

**Gamestate Existence Check**
- Function: `getGamestateByMonth(client, saveId, date)` in `src/db/gamestates.ts`
- Uses PostgreSQL `DATE_TRUNC('month', ...)` to compare dates by month
- Applies `startOfMonth()` (from date-fns) to incoming date only, not database date
- Example: File date `2200-04-18` matches database date `2200-04-01`
- Returns existing gamestate if found, undefined otherwise

**Gamestate Insertion**
- Function: `insertGamestate(client, saveId, date, data)` in `src/db/gamestates.ts`
- Inserts full parsed gamestate as JSONB into `data` column
- Enforces uniqueness constraint on `(save_id, date)` pair
- Returns inserted gamestate with `gamestateId` and `date`

#### Error Handling

- Try-catch wrapper around each parser iteration
- Errors logged with full context using Pino logger
- Failed iterations don't crash the parser - next iteration runs normally
- Database client properly released even on errors (try-finally pattern)

### Configuration

**Environment Variables:**
- `STELLARIS_STATS_PARSER_INTERVAL` - Milliseconds between parser iterations

**Data Location:**
- Save files stored at `/stellaris-data/<gamestateId>/ironman.sav`
- Each gamestate ID is a directory containing the save file

### Database Schema

**Save Table:**
```sql
CREATE TABLE save (
  save_id SERIAL PRIMARY KEY,
  filename VARCHAR(255) NOT NULL UNIQUE,
  name VARCHAR(255) NOT NULL
)
```

**Gamestate Table:**
```sql
CREATE TABLE gamestate (
  gamestate_id SERIAL PRIMARY KEY,
  save_id INTEGER NOT NULL,
  date TIMESTAMP WITH TIME ZONE NOT NULL,
  data JSONB NOT NULL,
  UNIQUE (save_id, date),
  FOREIGN KEY (save_id) REFERENCES save (save_id) ON DELETE CASCADE
)
```

## Budget Analysis Agent

The budget analysis agent is a Python-based AI agent that analyzes Stellaris empire budget data to detect sudden resource drops.

### Agent Architecture

#### Components

- **Budget Agent** (`agent/src/agent/budget_agent/agent.py`): Main agent with sudden drop detection
- **Tools** (`agent/src/agent/budget_agent/tools.py`): GraphQL data fetching and analysis functions
- **Models** (`agent/src/agent/budget_agent/models.py`): Pydantic models for structured outputs
- **CLI** (`agent/src/agent/cli.py`): Command-line interface entry point

#### Data Flow

1. User invokes CLI with save filename
2. Agent fetches the 4 most recent budget snapshots from GraphQL API
3. For each snapshot, sums resource values across all budget categories
4. Compares resource totals between first (D1) and last (D4) snapshots
5. Flags resources with 30%+ drops as sudden drops
6. Returns structured result with detected sudden drops

#### Configuration

- **Drop Threshold**: 30% drop triggers detection
- **Analysis Window**: 4 most recent datapoints (D1 to D4 comparison)
- **Model**: `openai:gpt-5.2-2025-12-11`
- **API Key**: `ANTHROPIC_API_KEY` or `STELLARIS_STATS_ANTHROPIC_API_KEY` environment variable (loaded via dotenvx from `.env.stellaris-stats.secrets`)

#### Structured Output

```python
class SuddenDropAnalysisResult(BaseModel):
    save_filename: str
    analysis_period_start: str
    analysis_period_end: str
    datapoints_analyzed: int
    drop_threshold_percent: float
    sudden_drops: list[SuddenDrop]
    summary: str
```

### Evaluation Framework

The agent includes a pydantic-evals based evaluation framework for testing agent behavior.

#### Components

- **Runner** (`agent/src/agent/evals/runner.py`): Orchestrates evaluation runs with mock GraphQL client
- **Mock Client** (`agent/src/agent/evals/mock_client.py`): Replaces live GraphQL with fixture data
- **Evaluators** (`agent/src/agent/evals/evaluators/`): Custom evaluators for output validation
- **Datasets** (`agent/src/agent/evals/datasets/`): Test cases with inputs and expected outcomes
- **CLI** (`agent/src/agent/evals/cli.py`): Command-line interface for running evals

#### Available Datasets

- `multi_agent_drop_detection`: Tests multi-agent workflow for detecting sudden resource drops and root cause analysis

#### Running Evals

```bash
npm run agent:evals -- --dataset multi_agent_drop_detection
npm run agent:evals -- --dataset multi_agent_drop_detection --model anthropic:claude-haiku-3-5-20241022
npm run agent:evals -- --list-datasets
npm run agent:evals -- --list-models
```

#### Adding New Datasets

1. Create fixture using `npm run agent:generate-fixture`
2. Add dataset file in `agent/src/agent/evals/datasets/`
3. Register in `agent/src/agent/evals/cli.py` AVAILABLE_DATASETS

### Python Unit Testing

The Python agent includes pytest-based unit tests for testing business logic without requiring API keys or network access.

#### Test Structure

- **Location**: `agent/tests/`
- **Framework**: pytest with pytest-asyncio for async support
- **Command**: `npm run test:python` (verbose) or `npm run test:ci:python` (CI mode)

#### Test Files

| File | Purpose |
|------|---------|
| `test_tools.py` | Pure function tests: `select_latest_dates()`, `get_gamestates_for_dates()` |
| `test_agent_functions.py` | Agent logic: `sum_resources_for_snapshot()`, prompt builders |
| `test_models.py` | Pydantic model validation |
| `test_mock_client.py` | MockClient and fixture loading tests |
| `test_evaluators.py` | NoResourceDrop/ResourceDrop evaluator logic |
| `test_tools_async.py` | Async functions: `get_available_dates()`, `list_saves()` |

#### Configuration

**pytest.ini_options in `agent/pyproject.toml`:**
```toml
[tool.pytest.ini_options]
asyncio_default_fixture_loop_scope = "function"
asyncio_mode = "auto"
filterwarnings = ["error", "ignore::DeprecationWarning"]
testpaths = ["tests"]
```

#### Shared Fixtures (`agent/tests/conftest.py`)

- `empty_mock_client`: Empty MockClient instance
- `sample_fixture_path`: Path to stable_energy_balance.json
- `sample_fixture`: Loaded Fixture from JSON
- `mock_client_from_fixture`: MockClient populated with fixture data
- `agent_deps`: AgentDeps with mock client

#### Mocking Strategy

Uses existing mock infrastructure from evals:
- `MockClient`: Dataclass-based mock implementing `GraphQLClientProtocol`
- `load_fixture()`: Loads JSON fixtures with GraphQL response data
- `create_mock_client()`: Creates MockClient from loaded fixture

This approach allows testing agent tools and logic without network calls or API keys.
