# Architecture & Technical Details

This document contains detailed technical documentation for the Stellaris Stats project architecture.

## GraphQL Caching System

The project implements a three-tier caching strategy using Redis to optimize GraphQL query performance for immutable game state data.

### Caching Architecture

#### Tier 1: Response-Level Caching

- **Implementation**: Custom Apollo Server plugin (`src/graphql/responseCache.ts`)
- **Class**: `RedisCache` implementing Apollo's `KeyValueCache` interface
- **Key Prefix**: `graphql:` for all cache entries
- **Key Format**: `graphql:{query-hash}:{variables-hash}` (auto-generated by Apollo)
- **Null Prevention**: Responses containing null values are NOT cached to prevent caching errors

#### Tier 2: Field-Level Caching

- **Implementation**: Manual caching in resolvers (`src/graphql/generated/Gamestate.ts`)
- **Cached Fields**:
  - `Gamestate.budget` - Key: `budget:gamestateId:{id}`
  - `Gamestate.planets` - Key: `planets:gamestateId:{id}`
- **Strategy**: Check cache first, on miss load via DataLoader and cache result
- **TTL**: No expiration (immutable data)

#### Tier 3: DataLoader Batching with Request-Scoped Cache

- **Location**: `src/graphql/dataloaders/`
- **DataLoaders**:
  - `budgetLoader`: Batches budget queries by gamestateId
  - `planetsLoader`: Batches planet queries by gamestateId
  - `gamestatesLoader`: Batches gamestate queries by saveId
- **Purpose**: Prevent N+1 query problems and provide request-level deduplication
- **Lifecycle**: Created per GraphQL request (request-scoped)
- **Database Functions**: Calls batch query functions like `getBudgetBatch()`, `getPlanetsBatch()`

### Redis Configuration

- **Client**: `ioredis` library configured in `src/redis.ts`
- **Environment Variables**:
  - `STELLARIS_STATS_REDIS_HOST` (default: 'redis')
  - `STELLARIS_STATS_REDIS_PORT` (default: 6379)
  - `STELLARIS_STATS_REDIS_DB` (default: 0)
- **Retry Strategy**: Exponential backoff (50ms × attempts, max 2000ms, 3 max retries)
- **Deployment**: Redis 7.4-alpine container with persistent volume storage, internal network only (no exposed ports)

### Cache Control Directives

- **GraphQL Schema**: Uses `@cacheControl` directive in `graphql/schema.graphql`
- **Cached Types**: `Budget` and `Gamestate` types marked with `@cacheControl` (no maxAge specified)
- **Default Behavior**: No caching unless explicit `@cacheControl` directive present
- **TTL Strategy**: No expiration for immutable types (game state data never changes once stored)

### Cache Invalidation

- **Current Implementation**: None
- **Rationale**: Game state data is immutable - once parsed and stored, it never changes
- **Considerations**: Redis memory may grow over time; consider implementing eviction policy (e.g., `allkeys-lru`) if needed

### Query Flow

```
GraphQL Query
  → Apollo Response Cache (check)
    → Resolver Field-Level Cache (check)
      → DataLoader Request Cache (check)
        → Batch Database Query
          → Store in all cache layers
            → Return result
```

## Testing Framework

The project uses end-to-end integration testing with complete database isolation, allowing tests to run in parallel without interference.

### Testing Architecture

#### Test Runner

- **Framework**: Bun (built-in test runner)
- **Test Files**: `tests/**/*.test.ts`
- **Command**: `npm run test:typescript` (uses `dotenvx` to load test environment)
- **Execution**: Parallel by default, each test fully isolated

#### Database Isolation Strategy

- **Pattern**: Database-per-test
- **Implementation**: Each test creates a unique PostgreSQL database using `crypto.randomUUID()`
- **Database Naming**: `stellaris_test_{uuid}` with hyphens replaced by underscores
- **Lifecycle**: Created in `beforeEach`, destroyed in `afterEach`
- **Migrations**: Automatically run on each test database using `node-pg-migrate`
- **Test Database Service**: Separate `db-test` PostgreSQL container in docker-compose

#### Test Infrastructure Components

##### 1. Test Database Manager (`tests/utils/testDatabase.ts`)

Creates and destroys isolated test databases:

```typescript
const testDb = await createTestDatabase()
// Returns: { pool: Pool, dbName: string, dbConfig: PoolConfig }

await destroyTestDatabase(testDb)
```

**Features:**

- Creates unique database with UUID-based name
- Runs all migrations automatically
- Provides dedicated connection pool
- Cleanup ensures no test database leaks

##### 2. Test Server Factory (`tests/utils/testServer.ts`)

Creates Apollo Server configured for testing:

```typescript
const testServer = createTestServer(testDb)
// Returns: { server, pool, cache, mockRedis, cleanup }
```

**Configuration:**

- Uses test database pool
- Mock Redis implementation (in-memory)
- All production plugins (response cache, cache control)
- Client release plugin (auto-releases connections)
- No HTTP layer (uses `executeOperation` directly)

##### 3. GraphQL Client Wrapper (`tests/utils/graphqlClient.ts`)

Type-safe GraphQL query execution:

```typescript
const result = await executeQuery<{
  saves: { filename: string }[]
}>(testServer, query, variables)
// Returns: { data?: T, errors?: GraphQLFormattedError[] }
```

**Features:**

- Creates proper GraphQL context per request
- Includes DataLoaders and cache
- Type-safe response with generics
- Automatic client release via server plugin

##### 4. Fixture Loader (`tests/utils/fixtures.ts`)

Loads SQL fixtures into test database:

```typescript
await loadFixture(testDb.pool, 'saves/basic-save.sql')
await loadFixtures(testDb.pool, ['saves/save1.sql', 'saves/save2.sql'])
```

**Fixture Pattern:**

- Located in `tests/fixtures/`
- Use subqueries for foreign key references
- Sequential execution to maintain FK dependencies
- Example: `(SELECT save_id FROM save WHERE filename = 'test.sav')`

##### 5. Mock Redis (`tests/utils/mockRedis.ts`)

In-memory Redis implementation:

- Implements same interface as `ioredis`
- Compatible with `RedisCache` wrapper
- No external dependencies
- Automatically cleared on cleanup

### Test Configuration

**Environment File**: `.devcontainer/.env.db.test`

```bash
STELLARIS_TEST_DB_HOST=db-test
STELLARIS_TEST_DB_PORT=5432
STELLARIS_TEST_DB_USER=stellaris_test
STELLARIS_TEST_DB_PASSWORD=stellaris_test
STELLARIS_TEST_DB_ADMIN_DATABASE=stellaris_test_admin
```

**Docker Compose**: Separate test database service

```yaml
db-test:
  image: postgres:18
  container_name: stellaris-stats_db-test
  env_file:
    - .env.db.test
  networks:
    - stellaris-stats-db-test-network
  volumes:
    - db-test-data:/var/lib/postgresql
```

### Key Implementation Details

**Context Creation Pattern:**

```typescript
const client = await pool.connect()
const contextValue: GraphQLServerContext = {
  client,
  loaders: createDataLoaders(client),
  cache,
}
```

**Client Lifecycle:**

- Client acquired from pool per GraphQL request
- Released automatically by server's `willSendResponse` plugin
- No manual `client.release()` needed in tests
- Tests must `await executeQuery` to ensure cleanup

**Server vs Production:**

- Test server has same plugins as production
- Uses `executeOperation()` instead of HTTP
- No `startStandaloneServer()` call
- Context created per operation, not pre-configured

**Database Naming Constraints:**

- PostgreSQL identifiers use underscores not hyphens
- UUID hyphens replaced: `randomUUID().replace(/-/g, '_')`
- Format: `stellaris_test_550e8400_e29b_41d4_a716_446655440000`

## Parser System

The parser is a background service that periodically reads Stellaris save files, extracts game state data, and stores it in PostgreSQL for analysis via the GraphQL API.

### Parser Architecture

#### Execution Model

- **Interval-Based**: Runs on a configurable interval defined by `STELLARIS_STATS_PARSER_INTERVAL` environment variable
- **Watch Mode**: Uses `tsx watch` for automatic restart on code changes during development
- **Command**: `npm run parser:run -- -g <gamestateId>` or `npm run parser:run -- -l` to list available saves

#### Key Components

**Configuration (`src/parser/parserConfig.ts`)**
- Defines parser-specific configuration schema
- Validates `STELLARIS_STATS_PARSER_INTERVAL` using Zod

**Main Parser (`src/parser/parserMain.ts`)**
- Orchestrates the parsing workflow
- Runs database migrations on startup
- Executes parsing loop at configured intervals
- Handles graceful shutdown (SIGTERM, SIGINT)

**Gamestate Reader (`src/parser/gamestateReader.ts`)**
- Extracts `gamestate` file from ZIP-compressed save files using yauzl-promise
- Returns gamestate data as `Uint8Array` for parsing

**Parser Options (`src/parser/parserOptions.ts`)**
- Parses command-line arguments using Commander
- Supports `-g <gamestateId>` to specify which save to parse
- Supports `-l` to list available gamestate IDs from `/stellaris-data` directory

#### Parsing Workflow

1. **Read Save File**: Extract gamestate from ZIP file at `/stellaris-data/<gamestateId>/ironman.sav`
2. **Parse with Jomini**: Convert Paradox Clausewitz format to JavaScript object
3. **Extract Metadata**: Parse `name` (empire name) and `date` (in-game date) from gamestate
4. **Begin Transaction**: Use `withTx()` helper to wrap all database operations in a transaction
5. **Upsert Save**: Create or update save row with filename (without .sav extension) and name
6. **Check Existence**: Query database for existing gamestate in the same month using `startOfMonth()` comparison
7. **Insert Gamestate**: If no gamestate exists for that month, insert new row with full parsed JSON as JSONB
8. **Populate Budget Tables**: Extract budget data from parsed object and insert into `budget_entry` and `budget_category` tables
9. **Commit Transaction**: Transaction automatically commits on success, rolls back on error

#### Budget Table Population

**Budget Data Extraction:**
- Player country ID: `parsed.player[0].country`
- Budget data path: `parsed.country[playerCountryId].budget.current_month`
- Structure: Three-level nested object with category types (`income`, `expenses`, `balance`), each containing category names (e.g., `country_base`, `armies`, `ships`), which contain resource fields (20 total: `energy`, `minerals`, `alloys`, etc.)

**Database Functions:**
- `populateBudgetTables(client, gamestateId, parsed, logger)` - Main orchestration function in `src/db/budget.ts`
- `insertBudgetEntry(client, entryData)` - Inserts budget_entry row with 20 resource columns, returns budget_entry_id
- `insertBudgetCategory(client, gamestateId, categoryType, categoryName, budgetEntryId)` - Links budget entry to gamestate

**Transaction Atomicity:**
- All parser operations (save upsert, gamestate insert, budget population) wrapped in single transaction using `withTx()` helper
- Ensures budget data is never orphaned from its gamestate
- If budget population fails unexpectedly, entire operation rolls back

**Graceful Error Handling:**
- Missing player country ID: Log warning, skip budget population
- Missing budget data: Log info, skip budget population (normal for some saves)
- Validation errors: Log error with context, skip budget population
- Unexpected errors: Transaction rolls back, error bubbles up
- Budget population is non-critical and won't fail parser iteration for missing/invalid data

#### Database Operations

**Save Management**
- Function: `upsertSave(client, filename, name)` in `src/db/save.ts`
- Uses `ON CONFLICT (filename) DO UPDATE` to handle duplicates
- Updates save name if it changes between parses

**Gamestate Existence Check**
- Function: `getGamestateByMonth(client, saveId, date)` in `src/db/gamestates.ts`
- Uses PostgreSQL `DATE_TRUNC('month', ...)` to compare dates by month
- Applies `startOfMonth()` (from date-fns) to incoming date only, not database date
- Example: File date `2200-04-18` matches database date `2200-04-01`
- Returns existing gamestate if found, undefined otherwise

**Gamestate Insertion**
- Function: `insertGamestate(client, saveId, date, data)` in `src/db/gamestates.ts`
- Inserts full parsed gamestate as JSONB into `data` column
- Enforces uniqueness constraint on `(save_id, date)` pair
- Returns inserted gamestate with `gamestateId` and `date`

#### Error Handling

- Try-catch wrapper around each parser iteration
- Errors logged with full context using Pino logger
- Failed iterations don't crash the parser - next iteration runs normally
- Database client properly released even on errors (try-finally pattern)

### Configuration

**Environment Variables:**
- `STELLARIS_STATS_PARSER_INTERVAL` - Milliseconds between parser iterations

**Data Location:**
- Save files stored at `/stellaris-data/<gamestateId>/ironman.sav`
- Each gamestate ID is a directory containing the save file

### Database Schema

**Save Table:**
```sql
CREATE TABLE save (
  save_id SERIAL PRIMARY KEY,
  filename VARCHAR(255) NOT NULL UNIQUE,
  name VARCHAR(255) NOT NULL
)
```

**Gamestate Table:**
```sql
CREATE TABLE gamestate (
  gamestate_id SERIAL PRIMARY KEY,
  save_id INTEGER NOT NULL,
  date TIMESTAMP WITH TIME ZONE NOT NULL,
  data JSONB NOT NULL,
  UNIQUE (save_id, date),
  FOREIGN KEY (save_id) REFERENCES save (save_id) ON DELETE CASCADE
)
```

## Budget Analysis Agent

The budget analysis agent is a Python-based AI agent that analyzes Stellaris empire budget data to identify sudden changes in resource production.

### Agent Architecture

#### Components

- **Budget Agent** (`agent/src/agent/budget_agent.py`): Main agent using Claude Sonnet 4 model
- **Tools** (`agent/src/agent/tools.py`): GraphQL data fetching and analysis functions
- **Models** (`agent/src/agent/models.py`): Pydantic models for structured outputs
- **CLI** (`agent/src/agent/cli.py`): Command-line interface entry point

#### Data Flow

1. User invokes CLI with save filename and optional threshold
2. Agent fetches available dates from GraphQL API
3. Finds comparison dates (latest vs ~1 year prior)
4. Fetches budget balance data for both dates
5. Compares all budget categories and resources
6. Returns structured result with changes exceeding threshold

#### Configuration

- **Default Threshold**: 15% change triggers detection
- **Comparison Scope**: Latest date vs approximately 1 year prior
- **Model**: `anthropic:claude-sonnet-4-5-20250929`
- **API Key**: `ANTHROPIC_API_KEY` or `STELLARIS_STATS_ANTHROPIC_API_KEY` environment variable (loaded via dotenvx from `.env.stellaris-stats.secrets`)

#### Structured Output

```python
class BudgetAnalysisResult(BaseModel):
    save_filename: str
    previous_date: str
    current_date: str
    threshold_percent: float
    sudden_changes: list[BudgetChange]
    summary: str
```

### Evaluation Framework

The agent includes a pydantic-evals based evaluation framework for testing agent behavior.

#### Components

- **Runner** (`agent/src/agent/evals/runner.py`): Orchestrates evaluation runs with mock GraphQL client
- **Mock Client** (`agent/src/agent/evals/mock_client.py`): Replaces live GraphQL with fixture data
- **Evaluators** (`agent/src/agent/evals/evaluators/`): Custom evaluators for output validation
- **Datasets** (`agent/src/agent/evals/datasets/`): Test cases with inputs and expected outcomes
- **CLI** (`agent/src/agent/evals/cli.py`): Command-line interface for running evals

#### Available Datasets

- `stable_budget_balance`: Tests that stable resources don't trigger false positive drops

#### Running Evals

```bash
npm run agent:evals -- --dataset stable_budget_balance
npm run agent:evals -- --dataset stable_budget_balance --model anthropic:claude-haiku-3-5-20241022
npm run agent:evals -- --list-datasets
npm run agent:evals -- --list-models
```

#### Adding New Datasets

1. Create fixture using `npm run agent:generate-fixture`
2. Add dataset file in `agent/src/agent/evals/datasets/`
3. Register in `agent/src/agent/evals/cli.py` AVAILABLE_DATASETS
